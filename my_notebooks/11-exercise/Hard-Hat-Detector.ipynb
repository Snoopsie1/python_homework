{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Hard Hat Detector\n",
    "\n",
    "### Initialize the Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\r\n",
      "----------------------------- -----------\r\n",
      "absl-py                       1.3.0\r\n",
      "alembic                       1.8.1\r\n",
      "altair                        4.2.0\r\n",
      "anyio                         3.6.2\r\n",
      "argon2-cffi                   21.3.0\r\n",
      "argon2-cffi-bindings          21.2.0\r\n",
      "asttokens                     2.0.8\r\n",
      "astunparse                    1.6.3\r\n",
      "async-generator               1.10\r\n",
      "attrs                         22.1.0\r\n",
      "Babel                         2.10.3\r\n",
      "backcall                      0.2.0\r\n",
      "backports.functools-lru-cache 1.6.4\r\n",
      "beautifulsoup4                4.11.1\r\n",
      "bleach                        5.0.1\r\n",
      "blinker                       1.5\r\n",
      "bokeh                         2.4.3\r\n",
      "Bottleneck                    1.3.5\r\n",
      "branca                        0.5.0\r\n",
      "brotlipy                      0.7.0\r\n",
      "cached-property               1.5.2\r\n",
      "cachetools                    5.2.0\r\n",
      "certifi                       2022.9.24\r\n",
      "certipy                       0.1.3\r\n",
      "cffi                          1.15.1\r\n",
      "charset-normalizer            2.1.1\r\n",
      "click                         8.1.3\r\n",
      "cloudpickle                   2.2.0\r\n",
      "colorama                      0.4.6\r\n",
      "conda                         22.9.0\r\n",
      "conda-package-handling        1.9.0\r\n",
      "contourpy                     1.0.6\r\n",
      "cryptography                  38.0.2\r\n",
      "cycler                        0.11.0\r\n",
      "Cython                        0.29.32\r\n",
      "cytoolz                       0.12.0\r\n",
      "dask                          2022.10.0\r\n",
      "dateparser                    1.1.3\r\n",
      "debugpy                       1.6.3\r\n",
      "decorator                     5.1.1\r\n",
      "defusedxml                    0.7.1\r\n",
      "dill                          0.3.6\r\n",
      "distributed                   2022.10.0\r\n",
      "entrypoints                   0.4\r\n",
      "et-xmlfile                    1.0.1\r\n",
      "executing                     1.1.1\r\n",
      "fastjsonschema                2.16.2\r\n",
      "flatbuffers                   22.10.26\r\n",
      "flit_core                     3.7.1\r\n",
      "folium                        0.13.0\r\n",
      "fonttools                     4.38.0\r\n",
      "fsspec                        2022.10.0\r\n",
      "gast                          0.4.0\r\n",
      "gmpy2                         2.1.2\r\n",
      "google-auth                   2.14.0\r\n",
      "google-auth-oauthlib          0.4.6\r\n",
      "google-pasta                  0.2.0\r\n",
      "graphviz                      0.20.1\r\n",
      "greenlet                      1.1.3.post0\r\n",
      "grpcio                        1.50.0\r\n",
      "h5py                          3.7.0\r\n",
      "HeapDict                      1.0.1\r\n",
      "html5lib                      1.1\r\n",
      "idna                          3.4\r\n",
      "imagecodecs                   2022.9.26\r\n",
      "imageio                       2.22.0\r\n",
      "importlib-metadata            5.0.0\r\n",
      "importlib-resources           5.10.0\r\n",
      "intel-openmp                  2022.2.0\r\n",
      "ipykernel                     6.17.0\r\n",
      "ipympl                        0.9.2\r\n",
      "ipython                       8.6.0\r\n",
      "ipython-genutils              0.2.0\r\n",
      "ipywidgets                    8.0.2\r\n",
      "jedi                          0.18.1\r\n",
      "Jinja2                        3.1.2\r\n",
      "joblib                        1.2.0\r\n",
      "json5                         0.9.5\r\n",
      "jsonschema                    4.16.0\r\n",
      "jupyter-client                7.3.4\r\n",
      "jupyter-console               6.4.4\r\n",
      "jupyter_core                  4.11.1\r\n",
      "jupyter-server                1.21.0\r\n",
      "jupyter-telemetry             0.1.0\r\n",
      "jupyterhub                    3.0.0\r\n",
      "jupyterlab                    3.5.0\r\n",
      "jupyterlab-pygments           0.2.2\r\n",
      "jupyterlab_server             2.16.2\r\n",
      "jupyterlab-widgets            3.0.3\r\n",
      "keras                         2.10.0\r\n",
      "Keras-Preprocessing           1.1.2\r\n",
      "kiwisolver                    1.4.4\r\n",
      "libclang                      14.0.6\r\n",
      "libmambapy                    0.27.0\r\n",
      "llvmlite                      0.39.1\r\n",
      "locket                        1.0.0\r\n",
      "lxml                          4.9.1\r\n",
      "lz4                           4.0.2\r\n",
      "Mako                          1.2.3\r\n",
      "mamba                         0.27.0\r\n",
      "Markdown                      3.4.1\r\n",
      "MarkupSafe                    2.1.1\r\n",
      "matplotlib                    3.6.1\r\n",
      "matplotlib-inline             0.1.6\r\n",
      "mistune                       2.0.4\r\n",
      "mkl                           2022.2.0\r\n",
      "mpmath                        1.2.1\r\n",
      "msgpack                       1.0.4\r\n",
      "munkres                       1.1.4\r\n",
      "nbclassic                     0.4.5\r\n",
      "nbclient                      0.7.0\r\n",
      "nbconvert                     7.2.3\r\n",
      "nbformat                      5.7.0\r\n",
      "nest-asyncio                  1.5.6\r\n",
      "networkx                      2.8.7\r\n",
      "notebook                      6.5.1\r\n",
      "notebook_shim                 0.2.0\r\n",
      "numba                         0.56.3\r\n",
      "numexpr                       2.8.3\r\n",
      "numpy                         1.23.4\r\n",
      "oauthlib                      3.2.2\r\n",
      "opencv-python                 4.6.0.66\r\n",
      "openpyxl                      3.0.10\r\n",
      "opt-einsum                    3.3.0\r\n",
      "packaging                     21.3\r\n",
      "pamela                        1.0.0\r\n",
      "pandas                        1.5.1\r\n",
      "pandocfilters                 1.5.0\r\n",
      "parso                         0.8.3\r\n",
      "partd                         1.3.0\r\n",
      "patsy                         0.5.3\r\n",
      "pexpect                       4.8.0\r\n",
      "pickleshare                   0.7.5\r\n",
      "Pillow                        9.2.0\r\n",
      "pip                           22.3\r\n",
      "pkgutil_resolve_name          1.3.10\r\n",
      "prometheus-client             0.15.0\r\n",
      "prompt-toolkit                3.0.31\r\n",
      "protobuf                      3.19.6\r\n",
      "psutil                        5.9.3\r\n",
      "ptyprocess                    0.7.0\r\n",
      "pure-eval                     0.2.2\r\n",
      "pyasn1                        0.4.8\r\n",
      "pyasn1-modules                0.2.8\r\n",
      "pycosat                       0.6.4\r\n",
      "pycparser                     2.21\r\n",
      "pycurl                        7.45.1\r\n",
      "pydantic                      1.10.2\r\n",
      "Pygments                      2.13.0\r\n",
      "PyJWT                         2.6.0\r\n",
      "pyOpenSSL                     22.1.0\r\n",
      "pyparsing                     3.0.9\r\n",
      "pyrsistent                    0.18.1\r\n",
      "PySocks                       1.7.1\r\n",
      "python-dateutil               2.8.2\r\n",
      "python-json-logger            2.0.1\r\n",
      "pytz                          2022.5\r\n",
      "pytz-deprecation-shim         0.1.0.post0\r\n",
      "PyWavelets                    1.3.0\r\n",
      "PyYAML                        6.0\r\n",
      "pyzmq                         24.0.1\r\n",
      "regex                         2022.3.2\r\n",
      "requests                      2.28.1\r\n",
      "requests-oauthlib             1.3.1\r\n",
      "rsa                           4.9\r\n",
      "ruamel.yaml                   0.17.21\r\n",
      "ruamel.yaml.clib              0.2.7\r\n",
      "ruamel-yaml-conda             0.15.80\r\n",
      "scikit-image                  0.19.3\r\n",
      "scikit-learn                  1.1.3\r\n",
      "scipy                         1.9.3\r\n",
      "seaborn                       0.12.0\r\n",
      "Send2Trash                    1.8.0\r\n",
      "setuptools                    65.5.0\r\n",
      "six                           1.16.0\r\n",
      "sniffio                       1.3.0\r\n",
      "sortedcontainers              2.4.0\r\n",
      "soupsieve                     2.3.2.post1\r\n",
      "SQLAlchemy                    1.4.42\r\n",
      "stack-data                    0.5.1\r\n",
      "statsmodels                   0.13.2\r\n",
      "sympy                         1.11.1\r\n",
      "tables                        3.7.0\r\n",
      "tbb                           2021.7.0\r\n",
      "tblib                         1.7.0\r\n",
      "tensorboard                   2.10.1\r\n",
      "tensorboard-data-server       0.6.1\r\n",
      "tensorboard-plugin-wit        1.8.1\r\n",
      "tensorflow                    2.10.0\r\n",
      "tensorflow-estimator          2.10.0\r\n",
      "tensorflow-io-gcs-filesystem  0.27.0\r\n",
      "termcolor                     2.1.0\r\n",
      "terminado                     0.17.0\r\n",
      "Theano                        1.0.5\r\n",
      "threadpoolctl                 3.1.0\r\n",
      "tifffile                      2022.10.10\r\n",
      "tinycss2                      1.2.1\r\n",
      "tomli                         2.0.1\r\n",
      "toolz                         0.12.0\r\n",
      "tornado                       6.1\r\n",
      "tqdm                          4.64.1\r\n",
      "traitlets                     5.5.0\r\n",
      "typing_extensions             4.4.0\r\n",
      "tzdata                        2022.6\r\n",
      "tzlocal                       4.2\r\n",
      "unicodedata2                  15.0.0\r\n",
      "urllib3                       1.26.11\r\n",
      "wcwidth                       0.2.5\r\n",
      "webencodings                  0.5.1\r\n",
      "websocket-client              1.4.1\r\n",
      "Werkzeug                      2.2.2\r\n",
      "wget                          3.2\r\n",
      "wheel                         0.37.1\r\n",
      "widgetsnbextension            4.0.3\r\n",
      "wrapt                         1.14.1\r\n",
      "xlrd                          2.0.1\r\n",
      "zict                          2.2.0\r\n",
      "zipp                          3.10.0\r\n"
     ]
    }
   ],
   "source": [
    "! pip list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xe but this version of numpy is 0xd",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;31mRuntimeError\u001B[0m: module compiled against API version 0xe but this version of numpy is 0xd"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "initialization failed",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;31mImportError\u001B[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mSystemError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;31mSystemError\u001B[0m: <built-in method __contains__ of dict object at 0x7f7dc721f800> returned a result with an error set",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcv2\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mcv\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mimageai\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mDetection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ObjectDetection\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrequests\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mreq\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/docker_notebooks/notebooks/venv/lib/python3.8/site-packages/imageai/Detection/__init__.py:8\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpltimage\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m backend \u001B[38;5;28;01mas\u001B[39;00m K\n",
      "File \u001B[0;32m~/Desktop/docker_notebooks/notebooks/venv/lib/python3.8/site-packages/tensorflow/__init__.py:37\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_typing\u001B[39;00m\n\u001B[0;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m module_util \u001B[38;5;28;01mas\u001B[39;00m _module_util\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlazy_loader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LazyLoader \u001B[38;5;28;01mas\u001B[39;00m _LazyLoader\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/docker_notebooks/notebooks/venv/lib/python3.8/site-packages/tensorflow/python/__init__.py:37\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001B[39;00m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# import it in modules_with_exports.py instead.\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# go/tf-wildcard-import\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pywrap_tensorflow \u001B[38;5;28;01mas\u001B[39;00m _pywrap_tensorflow\n\u001B[0;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m context\n\u001B[1;32m     39\u001B[0m \u001B[38;5;66;03m# pylint: enable=wildcard-import\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# Bring in subpackages.\u001B[39;00m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m data\n",
      "File \u001B[0;32m~/Desktop/docker_notebooks/notebooks/venv/lib/python3.8/site-packages/tensorflow/python/eager/context.py:35\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pywrap_tfe\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tf2\n\u001B[0;32m---> 35\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclient\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pywrap_tf_session\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m executor\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m monitoring\n",
      "File \u001B[0;32m~/Desktop/docker_notebooks/notebooks/venv/lib/python3.8/site-packages/tensorflow/python/client/pywrap_tf_session.py:19\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pywrap_tensorflow\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclient\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pywrap_tf_session\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclient\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pywrap_tf_session\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _TF_SetTarget\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclient\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pywrap_tf_session\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _TF_SetConfig\n",
      "\u001B[0;31mImportError\u001B[0m: initialization failed"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "from imageai.Detection import ObjectDetection\n",
    "\n",
    "import numpy as np\n",
    "import requests as req\n",
    "import os as os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Show Window Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def showImage(img):\n",
    "    window_name = 'image'\n",
    "    cv.imshow(window_name, img)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Download Data\n",
    "\n",
    "### Download Images of Hard Hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'req' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [1], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m hardhatLoc \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttp://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n03492922\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 3\u001B[0m hardhatImages \u001B[38;5;241m=\u001B[39m \u001B[43mreq\u001B[49m\u001B[38;5;241m.\u001B[39mget(hardhatLoc)\u001B[38;5;241m.\u001B[39mtext\n\u001B[1;32m      4\u001B[0m noOfImages \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhardhat\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "\u001B[0;31mNameError\u001B[0m: name 'req' is not defined"
     ]
    }
   ],
   "source": [
    "hardhatLoc = 'http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n03492922'\n",
    "\n",
    "hardhatImages = req.get(hardhatLoc).text\n",
    "noOfImages = 0\n",
    "\n",
    "if not os.path.exists('hardhat'):\n",
    "    os.makedirs('hardhat')\n",
    "\n",
    "for i in hardhatImages.split('\\n'):\n",
    "    try:\n",
    "        r = req.get(i, timeout=0.5)\n",
    "        file = i.split(\"/\")[-1].split('\\r')[0]\n",
    "        if 'image/jpeg' in r.headers['Content-Type']:\n",
    "            if len(r.content) > 8192:\n",
    "                with open('hardhat\\\\' + file, 'wb') as outfile:\n",
    "                    outfile.write(r.content)\n",
    "                    noOfImages += 1\n",
    "                    print('Success: ' + file)\n",
    "            else:\n",
    "                print('Failed: ' + file + ' -- Image too small')\n",
    "        else:\n",
    "            print('Failed: ' + file + ' -- Not an image')\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Failed: ' + file + ' -- Error')\n",
    "        \n",
    "print('*********** Download Finished **************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Download Images of People"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "peopleLoc = 'http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n07942152'\n",
    "\n",
    "peopleImages = req.get(peopleLoc).text\n",
    "noOfImages = 0\n",
    "\n",
    "if not os.path.exists('people'):\n",
    "    os.makedirs('people')\n",
    "\n",
    "for i in peopleImages.split('\\n'):\n",
    "    try:\n",
    "        r = req.get(i, timeout=0.5)\n",
    "        file = i.split(\"/\")[-1].split('\\r')[0]\n",
    "        if 'image/jpeg' in r.headers['Content-Type']:\n",
    "            if len(r.content) > 8192:\n",
    "                with open('people\\\\' + file, 'wb') as outfile:\n",
    "                    outfile.write(r.content)\n",
    "                    noOfImages += 1\n",
    "                    print('Success: ' + file)\n",
    "            else:\n",
    "                print('Failed: ' + file + ' -- Image too small')\n",
    "        else:\n",
    "            print('Failed: ' + file + ' -- Not an image')\n",
    "\n",
    "    except Exception as e:\n",
    "        print('Failed: ' + file + ' -- Error')\n",
    "        \n",
    "print('*********** Download Finished **************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Download Pre-Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "modelRetinaNet = 'https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/resnet50_coco_best_v2.0.1.h5'\n",
    "modelYOLOv3 = 'https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/yolo.h5'\n",
    "modelTinyYOLOv3 = 'https://github.com/OlafenwaMoses/ImageAI/releases/download/1.0/yolo-tiny.h5'\n",
    "\n",
    "if not os.path.exists('yolo.h5'):\n",
    "    r = req.get(modelYOLOv3, timeout=0.5)\n",
    "    with open('yolo.h5', 'wb') as outfile:\n",
    "        outfile.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train the Model\n",
    "\n",
    "### Define the Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From E:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "detector = ObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath('yolo.h5')\n",
    "detector.loadModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Ensure you specified correct input image, input type, output type and/or output image path ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPermissionError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[1;32mE:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\imageai\\Detection\\__init__.py\u001B[0m in \u001B[0;36mdetectCustomObjectsFromImage\u001B[1;34m(self, custom_objects, input_image, output_image_path, input_type, output_type, extract_detected_objects, minimum_percentage_probability, display_percentage_probability, display_object_name, thread_safe)\u001B[0m\n\u001B[0;32m    795\u001B[0m                     \u001B[1;32mif\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0minput_type\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"file\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 796\u001B[1;33m                         \u001B[0mimage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_image\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    797\u001B[0m                         \u001B[0minput_image\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mread_image_bgr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_image\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\PIL\\Image.py\u001B[0m in \u001B[0;36mopen\u001B[1;34m(fp, mode)\u001B[0m\n\u001B[0;32m   2842\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mfilename\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2843\u001B[1;33m         \u001B[0mfp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbuiltins\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"rb\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2844\u001B[0m         \u001B[0mexclusive_fp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mPermissionError\u001B[0m: [Errno 13] Permission denied: 'hardhat/test'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-6d8480a8c66a>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m     detectedImage, detections = detector.detectCustomObjectsFromImage(custom_objects=peopleOnly, output_type=\"array\",\n\u001B[0;32m      7\u001B[0m                                                                       \u001B[0minput_image\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mimageFile\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m                                                                       minimum_percentage_probability=30)\n\u001B[0m\u001B[0;32m      9\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdetections\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m         \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrename\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimageFile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"hardhat-clean/{0}\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\imageai\\Detection\\__init__.py\u001B[0m in \u001B[0;36mdetectCustomObjectsFromImage\u001B[1;34m(self, custom_objects, input_image, output_image_path, input_type, output_type, extract_detected_objects, minimum_percentage_probability, display_percentage_probability, display_object_name, thread_safe)\u001B[0m\n\u001B[0;32m    917\u001B[0m             \u001B[1;32mexcept\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    918\u001B[0m                 raise ValueError(\n\u001B[1;32m--> 919\u001B[1;33m                     \"Ensure you specified correct input image, input type, output type and/or output image path \")\n\u001B[0m\u001B[0;32m    920\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    921\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Ensure you specified correct input image, input type, output type and/or output image path "
     ]
    }
   ],
   "source": [
    "hardhatImages = os.listdir(\"hardhat\")\n",
    "peopleOnly = detector.CustomObjects(person=True)\n",
    "\n",
    "for i in hardhatImages:\n",
    "    imageFile = \"hardhat/{0}\".format(i)\n",
    "    detectedImage, detections = detector.detectCustomObjectsFromImage(custom_objects=peopleOnly, output_type=\"array\",\n",
    "                                                                      input_image=imageFile, \n",
    "                                                                      minimum_percentage_probability=30)\n",
    "    if len(detections) < 0:\n",
    "        os.remove(imageFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('hardhat/train/images'):\n",
    "    os.makedirs('hardhat/train/images')\n",
    "if not os.path.exists('hardhat/validation/images'):\n",
    "    os.makedirs('hardhat/validation/images')\n",
    "\n",
    "hardhatImages = os.listdir(\"hardhat\")\n",
    "hardhatTrainNums = round(len(hardhatImages) * 0.90)\n",
    "\n",
    "for i in range(0, hardhatTrainNums):\n",
    "    file = \"hardhat/\" + hardhatImages[i]\n",
    "    if os.path.isfile(file):\n",
    "        os.rename(file, \"hardhat/train/images/\" + hardhatImages[i])\n",
    "    \n",
    "hardhatImages = os.listdir(\"hardhat\")\n",
    "\n",
    "for i in hardhatImages:\n",
    "    file = \"hardhat/\" + i\n",
    "    if os.path.isfile(file):\n",
    "        os.rename(file, \"hardhat/validation/images/\" + i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating anchor boxes for training images and annotation...\n",
      "Average IOU for 9 anchors: 0.75\n",
      "Anchor Boxes generated.\n",
      "Detection configuration saved in  hardhat\\json\\detection_config.json\n",
      "Training on: \t['person hardhat']\n",
      "Training with Batch Size:  4\n",
      "Number of Experiments:  200\n",
      "Training with transfer learning from pretrained Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\keras\\callbacks\\callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "944/944 [==============================] - 856s 907ms/step - loss: 36.9858 - yolo_layer_16_loss: 7.0103 - yolo_layer_17_loss: 10.9458 - yolo_layer_18_loss: 19.0297 - val_loss: 22.8127 - val_yolo_layer_16_loss: 5.6805 - val_yolo_layer_17_loss: 6.6321 - val_yolo_layer_18_loss: 12.3109\n",
      "WARNING:tensorflow:From E:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/200\n",
      "944/944 [==============================] - 774s 820ms/step - loss: 20.2127 - yolo_layer_16_loss: 4.6473 - yolo_layer_17_loss: 5.6500 - yolo_layer_18_loss: 9.9154 - val_loss: 12.3263 - val_yolo_layer_16_loss: 5.5798 - val_yolo_layer_17_loss: 6.8109 - val_yolo_layer_18_loss: 11.0726\n",
      "Epoch 3/200\n",
      "944/944 [==============================] - 776s 822ms/step - loss: 18.3042 - yolo_layer_16_loss: 4.7082 - yolo_layer_17_loss: 4.9417 - yolo_layer_18_loss: 8.6543 - val_loss: 30.1679 - val_yolo_layer_16_loss: 3.5330 - val_yolo_layer_17_loss: 5.7483 - val_yolo_layer_18_loss: 10.3959\n",
      "Epoch 4/200\n",
      "944/944 [==============================] - 772s 817ms/step - loss: 15.8019 - yolo_layer_16_loss: 3.5019 - yolo_layer_17_loss: 4.2786 - yolo_layer_18_loss: 8.0214 - val_loss: 25.0318 - val_yolo_layer_16_loss: 3.3268 - val_yolo_layer_17_loss: 4.8476 - val_yolo_layer_18_loss: 8.9261\n",
      "Epoch 5/200\n",
      "944/944 [==============================] - 775s 821ms/step - loss: 14.2383 - yolo_layer_16_loss: 2.8789 - yolo_layer_17_loss: 3.9230 - yolo_layer_18_loss: 7.4365 - val_loss: 20.3871 - val_yolo_layer_16_loss: 2.7601 - val_yolo_layer_17_loss: 4.3188 - val_yolo_layer_18_loss: 8.2737\n",
      "Epoch 6/200\n",
      "944/944 [==============================] - 774s 820ms/step - loss: 13.3032 - yolo_layer_16_loss: 2.6941 - yolo_layer_17_loss: 3.6415 - yolo_layer_18_loss: 6.9677 - val_loss: 12.4483 - val_yolo_layer_16_loss: 2.4334 - val_yolo_layer_17_loss: 4.4343 - val_yolo_layer_18_loss: 7.3737\n",
      "Epoch 7/200\n",
      "944/944 [==============================] - 773s 819ms/step - loss: 12.7051 - yolo_layer_16_loss: 2.4235 - yolo_layer_17_loss: 3.3868 - yolo_layer_18_loss: 6.8948 - val_loss: 13.0070 - val_yolo_layer_16_loss: 2.1589 - val_yolo_layer_17_loss: 4.2864 - val_yolo_layer_18_loss: 7.7522\n",
      "Epoch 8/200\n",
      "944/944 [==============================] - 774s 820ms/step - loss: 12.0266 - yolo_layer_16_loss: 2.3517 - yolo_layer_17_loss: 3.1444 - yolo_layer_18_loss: 6.5304 - val_loss: 10.2641 - val_yolo_layer_16_loss: 2.4435 - val_yolo_layer_17_loss: 3.8413 - val_yolo_layer_18_loss: 7.1583\n",
      "Epoch 9/200\n",
      "944/944 [==============================] - 774s 819ms/step - loss: 11.5796 - yolo_layer_16_loss: 2.0791 - yolo_layer_17_loss: 3.0983 - yolo_layer_18_loss: 6.4023 - val_loss: 16.9550 - val_yolo_layer_16_loss: 1.9408 - val_yolo_layer_17_loss: 3.7394 - val_yolo_layer_18_loss: 8.5159\n",
      "Epoch 10/200\n",
      "944/944 [==============================] - 773s 819ms/step - loss: 11.0530 - yolo_layer_16_loss: 2.0455 - yolo_layer_17_loss: 2.9342 - yolo_layer_18_loss: 6.0733 - val_loss: 11.9410 - val_yolo_layer_16_loss: 2.4114 - val_yolo_layer_17_loss: 3.6174 - val_yolo_layer_18_loss: 7.4209\n",
      "Epoch 11/200\n",
      "944/944 [==============================] - 776s 822ms/step - loss: 10.6817 - yolo_layer_16_loss: 1.9981 - yolo_layer_17_loss: 2.8343 - yolo_layer_18_loss: 5.8493 - val_loss: 7.0664 - val_yolo_layer_16_loss: 1.9985 - val_yolo_layer_17_loss: 3.6278 - val_yolo_layer_18_loss: 6.6847\n",
      "Epoch 12/200\n",
      "944/944 [==============================] - 774s 820ms/step - loss: 10.4226 - yolo_layer_16_loss: 1.9022 - yolo_layer_17_loss: 2.7187 - yolo_layer_18_loss: 5.8017 - val_loss: 13.9414 - val_yolo_layer_16_loss: 2.1432 - val_yolo_layer_17_loss: 3.8370 - val_yolo_layer_18_loss: 6.8831\n",
      "Epoch 13/200\n",
      "944/944 [==============================] - 775s 821ms/step - loss: 10.0310 - yolo_layer_16_loss: 1.8245 - yolo_layer_17_loss: 2.6859 - yolo_layer_18_loss: 5.5206 - val_loss: 11.2866 - val_yolo_layer_16_loss: 1.8409 - val_yolo_layer_17_loss: 3.3783 - val_yolo_layer_18_loss: 6.5706\n",
      "Epoch 14/200\n",
      "944/944 [==============================] - 775s 821ms/step - loss: 9.7983 - yolo_layer_16_loss: 1.7165 - yolo_layer_17_loss: 2.5344 - yolo_layer_18_loss: 5.5474 - val_loss: 15.4132 - val_yolo_layer_16_loss: 1.7203 - val_yolo_layer_17_loss: 3.8468 - val_yolo_layer_18_loss: 6.7124\n",
      "Epoch 15/200\n",
      "944/944 [==============================] - 774s 820ms/step - loss: 9.6199 - yolo_layer_16_loss: 1.6960 - yolo_layer_17_loss: 2.5321 - yolo_layer_18_loss: 5.3918 - val_loss: 11.7558 - val_yolo_layer_16_loss: 1.6791 - val_yolo_layer_17_loss: 3.3249 - val_yolo_layer_18_loss: 6.7528\n",
      "Epoch 16/200\n",
      "944/944 [==============================] - 778s 824ms/step - loss: 9.2273 - yolo_layer_16_loss: 1.6217 - yolo_layer_17_loss: 2.3432 - yolo_layer_18_loss: 5.2624 - val_loss: 17.8903 - val_yolo_layer_16_loss: 1.8734 - val_yolo_layer_17_loss: 3.7065 - val_yolo_layer_18_loss: 6.7896\n",
      "Epoch 17/200\n",
      "944/944 [==============================] - 778s 825ms/step - loss: 9.0276 - yolo_layer_16_loss: 1.5986 - yolo_layer_17_loss: 2.3144 - yolo_layer_18_loss: 5.1147 - val_loss: 8.6253 - val_yolo_layer_16_loss: 1.6680 - val_yolo_layer_17_loss: 3.7442 - val_yolo_layer_18_loss: 5.6655\n",
      "Epoch 18/200\n",
      "944/944 [==============================] - 780s 827ms/step - loss: 8.8141 - yolo_layer_16_loss: 1.5611 - yolo_layer_17_loss: 2.3312 - yolo_layer_18_loss: 4.9219 - val_loss: 6.8751 - val_yolo_layer_16_loss: 1.4509 - val_yolo_layer_17_loss: 3.2254 - val_yolo_layer_18_loss: 6.5645\n",
      "Epoch 19/200\n",
      "944/944 [==============================] - 779s 825ms/step - loss: 8.6509 - yolo_layer_16_loss: 1.5625 - yolo_layer_17_loss: 2.2129 - yolo_layer_18_loss: 4.8754 - val_loss: 4.2779 - val_yolo_layer_16_loss: 1.4135 - val_yolo_layer_17_loss: 3.0607 - val_yolo_layer_18_loss: 6.1202\n",
      "Epoch 20/200\n",
      "944/944 [==============================] - 812s 860ms/step - loss: 8.4625 - yolo_layer_16_loss: 1.4308 - yolo_layer_17_loss: 2.1983 - yolo_layer_18_loss: 4.8334 - val_loss: 19.4190 - val_yolo_layer_16_loss: 1.4224 - val_yolo_layer_17_loss: 3.5843 - val_yolo_layer_18_loss: 7.1598\n",
      "Epoch 21/200\n",
      "944/944 [==============================] - 824s 872ms/step - loss: 8.3525 - yolo_layer_16_loss: 1.4480 - yolo_layer_17_loss: 2.2054 - yolo_layer_18_loss: 4.6992 - val_loss: 14.1312 - val_yolo_layer_16_loss: 1.6272 - val_yolo_layer_17_loss: 2.7905 - val_yolo_layer_18_loss: 5.9421\n",
      "Epoch 22/200\n",
      "682/944 [====================>.........] - ETA: 3:37 - loss: 8.1493 - yolo_layer_16_loss: 1.3431 - yolo_layer_17_loss: 2.0674 - yolo_layer_18_loss: 4.7388"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-21-cdca61b8cf02>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m                        train_from_pretrained_model=\"yolo.h5\")\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m \u001B[0mtrainer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrainModel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mE:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\imageai\\Detection\\Custom\\__init__.py\u001B[0m in \u001B[0;36mtrainModel\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    289\u001B[0m             \u001B[0mcallbacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    290\u001B[0m             \u001B[0mworkers\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 291\u001B[1;33m             \u001B[0mmax_queue_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m8\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    292\u001B[0m         )\n\u001B[0;32m    293\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     89\u001B[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001B[0;32m     90\u001B[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001B[1;32m---> 91\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     92\u001B[0m         \u001B[0mwrapper\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_original_function\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     93\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit_generator\u001B[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001B[0m\n\u001B[0;32m   1730\u001B[0m             \u001B[0muse_multiprocessing\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0muse_multiprocessing\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1731\u001B[0m             \u001B[0mshuffle\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mshuffle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1732\u001B[1;33m             initial_epoch=initial_epoch)\n\u001B[0m\u001B[0;32m   1733\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0minterfaces\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlegacy_generator_methods_support\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\keras\\engine\\training_generator.py\u001B[0m in \u001B[0;36mfit_generator\u001B[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001B[0m\n\u001B[0;32m    218\u001B[0m                                             \u001B[0msample_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    219\u001B[0m                                             \u001B[0mclass_weight\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mclass_weight\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 220\u001B[1;33m                                             reset_metrics=False)\n\u001B[0m\u001B[0;32m    221\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    222\u001B[0m                 \u001B[0mouts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mto_list\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mouts\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mtrain_on_batch\u001B[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001B[0m\n\u001B[0;32m   1512\u001B[0m             \u001B[0mins\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mx\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0my\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0msample_weights\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1513\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_train_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1514\u001B[1;33m         \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mins\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1515\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1516\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mreset_metrics\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mE:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m   3474\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3475\u001B[0m     fetched = self._callable_fn(*array_vals,\n\u001B[1;32m-> 3476\u001B[1;33m                                 run_metadata=self.run_metadata)\n\u001B[0m\u001B[0;32m   3477\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call_fetch_callbacks\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfetched\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_fetches\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3478\u001B[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001B[1;32mE:\\Development\\Anaconda\\envs\\ImageAI\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1470\u001B[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001B[0;32m   1471\u001B[0m                                                \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_handle\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1472\u001B[1;33m                                                run_metadata_ptr)\n\u001B[0m\u001B[0;32m   1473\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mrun_metadata\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1474\u001B[0m           \u001B[0mproto_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf_session\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTF_GetBuffer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrun_metadata_ptr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from imageai.Detection.Custom import DetectionModelTrainer\n",
    "\n",
    "trainer = DetectionModelTrainer()\n",
    "trainer.setModelTypeAsYOLOv3()\n",
    "trainer.setDataDirectory(data_directory=\"hardhat\")\n",
    "\n",
    "trainer.setTrainConfig(object_names_array=[\"person hardhat\"], batch_size=4, num_experiments=200, \n",
    "                       train_from_pretrained_model=\"yolo.h5\")\n",
    "\n",
    "trainer.trainModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Model evaluation....\n",
      "Model File:  hardhat\\models\\detection_model-ex-005--loss-0014.238.h5 \n",
      "\n",
      "Using IoU :  0.5\n",
      "Using Object Threshold :  0.3\n",
      "Using Non-Maximum Suppression :  0.5\n",
      "person hardhat: 0.7165\n",
      "mAP: 0.7165\n",
      "===============================\n",
      "Starting Model evaluation....\n",
      "Model File:  hardhat\\models\\detection_model-ex-010--loss-0011.053.h5 \n",
      "\n",
      "Using IoU :  0.5\n",
      "Using Object Threshold :  0.3\n",
      "Using Non-Maximum Suppression :  0.5\n",
      "person hardhat: 0.7865\n",
      "mAP: 0.7865\n",
      "===============================\n",
      "Starting Model evaluation....\n",
      "Model File:  hardhat\\models\\detection_model-ex-015--loss-0009.620.h5 \n",
      "\n",
      "Using IoU :  0.5\n",
      "Using Object Threshold :  0.3\n",
      "Using Non-Maximum Suppression :  0.5\n",
      "person hardhat: 0.8355\n",
      "mAP: 0.8355\n",
      "===============================\n",
      "Starting Model evaluation....\n",
      "Model File:  hardhat\\models\\detection_model-ex-020--loss-0008.462.h5 \n",
      "\n",
      "Using IoU :  0.5\n",
      "Using Object Threshold :  0.3\n",
      "Using Non-Maximum Suppression :  0.5\n",
      "person hardhat: 0.8446\n",
      "mAP: 0.8446\n",
      "===============================\n",
      "---------------------------------------------------------\n",
      "Iteration 05: 0.7164811838244572 Iteration 10: 0.786450228152799 Iteration 15: 0.8354553845774733 Iteration 20: 0.8446486610895216\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model05 = trainer.evaluateModel(model_path=\"hardhat\\models\\detection_model-ex-005--loss-0014.238.h5\", \n",
    "                      json_path=\"hardhat\\json\\detection_config.json\", iou_threshold=0.5, \n",
    "                      object_threshold=0.3, nms_threshold=0.5)\n",
    "model10 = trainer.evaluateModel(model_path=\"hardhat\\models\\detection_model-ex-010--loss-0011.053.h5\", \n",
    "                      json_path=\"hardhat\\json\\detection_config.json\", iou_threshold=0.5, \n",
    "                      object_threshold=0.3, nms_threshold=0.5)\n",
    "model15 = trainer.evaluateModel(model_path=\"hardhat\\models\\detection_model-ex-015--loss-0009.620.h5\", \n",
    "                      json_path=\"hardhat\\json\\detection_config.json\", iou_threshold=0.5, \n",
    "                      object_threshold=0.3, nms_threshold=0.5)\n",
    "model20 = trainer.evaluateModel(model_path=\"hardhat\\models\\detection_model-ex-020--loss-0008.462.h5\", \n",
    "                      json_path=\"hardhat\\json\\detection_config.json\", iou_threshold=0.5, \n",
    "                      object_threshold=0.3, nms_threshold=0.5)\n",
    "\n",
    "print('---------------------------------------------------------')\n",
    "print('Iteration 05:', model05[0]['average_precision']['person hardhat'],\n",
    "     'Iteration 10:', model10[0]['average_precision']['person hardhat'],\n",
    "     'Iteration 15:', model15[0]['average_precision']['person hardhat'],\n",
    "     'Iteration 20:', model20[0]['average_precision']['person hardhat'])\n",
    "print('---------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Random Hard Hat Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person hardhat  :  48.9349365234375  :  [198, 16, 253, 127]\n",
      "--------------------------------\n",
      "person hardhat  :  92.02308058738708  :  [84, 71, 127, 114]\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection.Custom import CustomObjectDetection\n",
    "\n",
    "detector = CustomObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "detector.setModelPath(\"hardhat\\models\\detection_model-ex-020--loss-0008.462.h5\")\n",
    "detector.setJsonPath(\"hardhat\\json\\detection_config.json\")\n",
    "detector.loadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person hardhat  :  81.50655627250671  :  [137, 74, 194, 119]\n",
      "--------------------------------\n",
      "person hardhat  :  64.44770097732544  :  [290, 89, 328, 123]\n",
      "--------------------------------\n",
      "person hardhat  :  70.66482901573181  :  [252, 90, 290, 130]\n",
      "--------------------------------\n",
      "person hardhat  :  54.37401533126831  :  [358, 93, 385, 131]\n",
      "--------------------------------\n",
      "person hardhat  :  59.80772376060486  :  [125, 100, 145, 136]\n",
      "--------------------------------\n",
      "person hardhat  :  45.671346783638  :  [222, 101, 249, 130]\n",
      "--------------------------------\n",
      "person hardhat  :  77.1479070186615  :  [314, 99, 361, 142]\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "testImages = os.listdir(\"hardhat/validation/images\")\n",
    "randomFile = testImages[random.randint(0, len(testImages) - 1)]\n",
    "\n",
    "detectedImage, detections = detector.detectObjectsFromImage(output_type=\"array\", \n",
    "                                                            input_image=\"hardhat/validation/images/{0}\".format(randomFile), \n",
    "                                                            minimum_percentage_probability=30)\n",
    "showImage(detectedImage)\n",
    "\n",
    "for eachObject in detections:\n",
    "    print(eachObject[\"name\"] , \" : \", eachObject[\"percentage_probability\"], \" : \", eachObject[\"box_points\"] )\n",
    "    print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}